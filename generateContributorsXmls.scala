import java.io.{ File, FileWriter, BufferedWriter, PrintWriter }
import scala.xml._
import scala.xml.parsing._
import org.alfresco.util.ISO9075

val newFolder = "gef_corrected"
val file = new File("MultipleLocationWriters.xml") //File generated by duplicate_team_different_region.scala
val gef_folder = "gef" //folder containing all the GEF articles - currently a relative path (subfolder)
val prettyPrinter = new PrettyPrinter(200, 4)

println("Loading in MultipleLocationWriters.xml")
// NOTE (JF St-Germain - Thu Sep 29 11:28:58 2011) :
// Replaced the usage of scala.xml.XML.loadFile(file) since it 
// parses <!CDATA[]> sections to escaped plain text
val document = ConstructingParser.fromSource(scala.io.Source.fromFile("MultipleLocationWriters.xml"), false).document.docElem

println("Splitting duplicates/outdated contributors")
val (contributorsNodes, duplicateNodes) = {
	(document \ "contributor") partition { c1 => (c1.attributes find { _.key == "ref" }) == None }
}
val contributors = contributorsNodes map { c =>
	new Contributor(
		(c \ "name").head.text,
		(c \ "region").toList map { r => new Region(r.text, r.attribute("count").get.toString.toInt) })
}

//Split all the contributors across multiple pages so that Python scripts can handle it.
val paginatedContributors = contributors.grouped(30).toList
println("Outputting contributors (excluding the duplicates)")
for (page:Seq[Contributor] <- paginatedContributors) {
	val contributorsOutput = newFolder + "/contents_gef_step2_allContributors_page" + paginatedContributors.indexOf(page) + ".xml" //File to output contributors to.
	println("Outputting contributor file %s of %s to: %s " format (paginatedContributors.indexOf(page), paginatedContributors.size, contributorsOutput))
	val output = new FileWriter(contributorsOutput)
	var formattedXml = new StringBuilder

    //convert contributors to XML, and pass them as an argument to ouput.println
	prettyPrinter.format(
      <contents>
        { page map { _.toXML } }       
      </contents>, formattedXml)

	output.write(formattedXml.toString)
    output.close
}

class Region(val name: String, val count: Int)
class Contributor(val name: String, var regions: List[Region], var references: List[Contributor] = List()) {
	def toXML = {
		val name = this.name
		val region: Option[Region] = try {
			Some(this.regions filter { _.name != "" } sortWith { _.count > _.count } head)
		} catch {
			case _ =>
				None
		}
		val deletedRegions = this.regions filter { _ != region.getOrElse(None) }

        // NOTE (JF St-Germain - Wed Oct  5 15:57:40 2011) :
        // Not sure if the writer name must be encoded...
		/*<content path="/views/gef/team" typeName="gef_team" key={ "gef_team_" + ISO9075.encode(name) }>*/
 	    <content path="/views/gef/team" typeName="gef_team" key={ "gef_team_" + name.replace(".","_") }>         
          { if (!deletedRegions.isEmpty) new scala.xml.Comment("Removed: " + (deletedRegions map { i => if (i.name == "") "<empty location>" else i.name }).mkString(", ")) }
			<element key="skip:validation">true</element>
			<element key="type">msfm:featureContent</element>
			<element key="contextNodeXPath">mspub:live_content</element>
			<element key="vdocfield-sitepub:title">{ PCData(name) }</element>
			{ if (region.isDefined) <element key="vdocfield-###SITE_NS###:gef_team_region">{ PCData(region.get.name) }</element> }
            <element key="prop-msfm:feature">false</element>
			<files/>
		</content>
	}
}

//Read in all GEF Articles and output then with any duplicate contributors updated/removed.
type DuplicateContributor = Tuple2[String, List[String]] //Type alias, could make DuplicateContributor a full blown type, but want a tuple anyway (as that's what maps are made of)
val referencesMap = new scala.collection.mutable.HashMap[String, List[String]] //Manual corrections for wrong names
println("Generating map of duplicate nodes")
duplicateNodes foreach { n =>
	{
		val correctName = n.attribute("ref").get text
		val wrongName = (n \ "name" text)
		referencesMap.synchronized {
			referencesMap(correctName) = wrongName :: referencesMap.get(correctName).getOrElse(List())
		}
	}
}
println("Reversing duplicates map")
val duplicateMap = { //For updating article XMLs with wrong names.
	referencesMap map { t =>
		{
			val correctName = t._1;
			val wrongNames = t._2;
			wrongNames map { _ -> correctName }
		}
	} flatten
} toMap

//##### ARTICLES

println("Importing all the articles and article lists")
val files = (new File(gef_folder).listFiles filter { _.getName startsWith "contents_gef_all_in_one" })
val paginatedFiles = files.grouped(30).toList //Each file could contain multiple articles

println("Outputting articles (any references to duplicate contributors updated)")
paginatedFiles.foreach { setOfFiles =>
	val articles = articleNodesFromFiles(setOfFiles)
	val updatedArticles = articles map { correctArticle(_, duplicateMap) }
    val outputFileName = newFolder + "/contents_gef_step4_allArticles_page" + paginatedFiles.indexOf(setOfFiles) + ".xml"
	val output = new FileWriter(outputFileName) //File to output contributors to.

	println("Outputting contributor file %s of %s to: %s " format (paginatedFiles.indexOf(setOfFiles), paginatedFiles.size, outputFileName))
	var formattedXml = new StringBuilder
	prettyPrinter.format(<contents>{ updatedArticles }</contents>, formattedXml)
	output.write(formattedXml.toString)
	output.close
}

def articleNodesFromFiles(files: Seq[java.io.File]) = {
	files.map { file =>
        // NOTE (JF St-Germain - Thu Sep 29 11:30:35 2011) :
        // Watch out for specifying the encoding.  The encoding is not detected automatically
        // with ConstructingParser
        val nodes = ConstructingParser.fromSource(scala.io.Source.fromFile(file)(scala.io.Codec.ISO8859), false).document.docElem \ "content"
		nodes filter { _.attribute("typeName").get.toString == "gef_article" }
	}.flatten
}
def correctArticle(a: xml.Node, duplicateMap: Map[String, String]): xml.Node = {
	try {
		val linkedWriters = (a \ "element").map { //For each <element> within the article (<content), convert it to...
			_.attribute("linked") //...its' "linked" attribute... which only article writers have. This returns Option[Seq[scala.xml.Node]] for each element
		}.flatten.map { //Flatten Option[Seq[Node]] to List[Node] ...then convert to...
			_.text.replace("gef_team_", "") //Get textual value of attribute, and remove gef_team from the beginning
		}

		def getFieldValues(field: String) = { //Get the value of a given element in the content
			val content = a
			(content \ "element").filter {
				_.attributes.find { a => a.key == "key" && a.value.text.contains(field) }.isDefined
			} map {
				_.text
			}
		}

        // NOTE (JF St-Germain - Thu Sep 29 15:46:58 2011) :
        // Fixes non escaped gef_team link names
        def fixArticleWriters(node :Node) :Node = {
          node match {
            case element @ <element/> if (element \ "@contentTextNode" text) == "sitemsdotcom_gef_article_writer" =>
              <element linked={ "gef_team_" + (element \ "@linked" text).replace("gef_team_", "") } contentTextNode="sitemsdotcom_gef_article_writer"/>
              /*<element linked={ "gef_team_" + ISO9075.encode((element \ "@linked" text).replace("gef_team_", "")) } contentTextNode="sitemsdotcom_gef_article_writer"/>
              */
            case Elem(prefix, label, attribs, scope, children @ _*) => Elem(prefix,
              label, attribs, scope, children map (fixArticleWriters(_)):_*)
            case other => other
          }
        }

		if (linkedWriters.exists(duplicateMap.contains)) { //Check if map contains an entry for any of the linked writers...create new article if so
			<content parent={ a.attribute("parent").get } typeName="gef_article" key={ a.attribute("key").get } oldFile={ a.attribute("oldFile").get }>
				<element key="skip:validation">true</element>
				<element key="type">msfm:orderedContent</element>
				<element key="vdocfield-sitepub:title">{ PCData(getFieldValues("sitepub:title").head) }</element>
				{
					for (country <- getFieldValues("gef_article_country")) yield <element key="vdocfield-###SITE_NS###:gef_article_country">{ PCData(country) }</element>
				}
				{
					for (body <- getFieldValues("body")) yield <element key="vdocfield-###SITE_NS###:body">{ PCData(body) }</element>
				}
				{
					for (article_abstract <- getFieldValues("abstract")) yield <element key="vdocfield-sitepub:abstract">{ PCData(article_abstract) }</element>
				}
				{
					for (article_order <- getFieldValues("prop-mspub:order")) yield <element key="prop-mspub:order">{ article_order }</element>
				}
				{
					for (writer <- linkedWriters) yield {
						val name = if (duplicateMap.contains(writer)) duplicateMap(writer) else writer
						<element linked={ "gef_team_" + name.replace(".","_") } contentTextNode="sitemsdotcom_gef_article_writer"/>
                        /*
                        <element linked={ "gef_team_" + name } contentTextNode="sitemsdotcom_gef_article_writer"/>
                        */

					}
				}
				<files/>
			</content>
		} else {
          fixArticleWriters(a)
		}
	} catch {
		case e: MatchError => {
			System.err.println("MatchError when trying to update contributors references in: %s" format a)
			a
		}
	}
}

//#####ARTICLE LISTS

println("Output Article Lists to new folder.")
def hasDisclosureText(contentNode :Node) = {
  (contentNode \\ "element").find {
    case element @ <element>{text}</element> if (element \ "@key" text) == "vdocfield-###SITE_NS###:disclosures" && text != "" => true
    case other => false
  } != None
}    

val articleLists = {
	files.map { file =>
        print(".")
        val nodes = ConstructingParser.fromSource(scala.io.Source.fromFile(file)(scala.io.Codec.ISO8859), false).document.docElem \ "content"
		nodes filter { _.attribute("typeName").get.toString == "gef_article_list" }
	}.flatten
}.groupBy { //Generate map (by Key/Date - allows us to get unique rticle lists)
	(_: xml.Node).attribute("key").get.toString
}.values map {
  _.head
  // NOTE (JF St-Germain - Fri Oct  7 09:50:57 2011) :
  // Seems like the disclosure clause is hardcoded.  
  // Removing import logic
  /*
  nodeCollection =>
  val nodeWithDisclosure = nodeCollection.find { hasDisclosureText }
  if (nodeWithDisclosure == None)
    nodeCollection.head
  else 
    nodeWithDisclosure.get
  */
}

//}.values map { _.head } //Get just values from map, and get head of each list of articlelists (they're all the same)

val articleListsFile = newFolder + "/contents_gef_step3_allArticleLists.xml" //File to output contributors to.
println("\n\nOutputting article lists to: %s" format articleListsFile)
val output = new FileWriter(articleListsFile)
var formattedXml = new StringBuilder
prettyPrinter.format(<contents>{ articleLists }</contents>, formattedXml)

output.write(formattedXml.toString)
output.close

import org.apache.commons.io.FileUtils
val featuredTeams = (new File(gef_folder).listFiles filter { _.getName startsWith "contents_gef_featured_team_" })
val targetFolder = new File(newFolder + "/featured_team")

println("Copying featured teams")
featuredTeams.foreach(file => FileUtils.copyFile(file, new File(newFolder  + "/" + file.getName().replace("contents_gef", "contents_gef_step1"))))

//featuredTeams.foreach(FileUtils.copyFileToDirectory(_, targetFolder))

println("Done")

